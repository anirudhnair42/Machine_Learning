{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS156_Assignment_4_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeM1ExtNtON"
      },
      "source": [
        "# **Assignment 4**\n",
        "## **CS156** | **Prof. Sterne**\n",
        "### Anirudh Nair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X1XKKOwSyAh"
      },
      "source": [
        "Link to assignment: https://colab.research.google.com/drive/1LyO8SpGzwzgX7Ynjzha09p68FuaLa_Z5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XHZpEQIN4bE"
      },
      "source": [
        "## Part 1: Loading the data and cleaning it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyFZrOIh7wTA"
      },
      "source": [
        "#importing the required libraries\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyFpacCf75xj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d578bf7e-b457-4e1d-c19d-2d086881e294"
      },
      "source": [
        "#downloading the datasets from the mnist dataset and loading them into x and y datasets\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "x = mnist[\"data\"]\n",
        "y = mnist[\"target\"]\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txpm1RcN73ea"
      },
      "source": [
        "#splitting the data for training and testing with proper propotions\n",
        "x_train = x[2000:10000]\n",
        "x_test = x[:2000]\n",
        "y_train = y[2000:10000]\n",
        "y_test = y[:2000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfJpUt6y8PMT"
      },
      "source": [
        "#customizing the dataset to only include the digits we are aiming to qualify\n",
        "train_locations = np.where(np.logical_or(y_train == '5' , y_train == '8' ))\n",
        "xtrain = x_train[train_locations] #Slicing Training Set \n",
        "ytrain = y_train[train_locations] #Slicing Test Set\n",
        "\n",
        "test_locations = np.where(np.logical_or(y_test == '5' , y_test == '8' ))\n",
        "xtest = x_test[test_locations]\n",
        "ytest = y_test[test_locations]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GO2gvnk8R0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7bdf270-ce09-4ade-bac5-dca14379378a"
      },
      "source": [
        "#checking the propotion of testing and training data\n",
        "print(\"Lenghths of the training set data:\", len(xtrain), \",\" ,len(ytrain))\n",
        "print(\"Length of testing set data\", len(xtest), \",\" ,len(ytest))\n",
        "print(\"Test set proportion: \", float(len(xtest))/(len(xtrain)+len(xtest)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lenghths of the training set data: 1455 , 1455\n",
            "Length of testing set data 352 , 352\n",
            "Test set proportion:  0.19479800774764802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbyPw658Tfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "358c5793-ae18-4d35-f7e1-96ea8b7f2e3f"
      },
      "source": [
        "#plotting the image\n",
        "digit1 = xtest[100]\n",
        "digit1_plot = digit1.reshape(28, 28)\n",
        "\n",
        "plt.imshow(digit1_plot, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
        "plt.axis(\"on\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngrADQRB2IAjCDgRB2IEgCDsQBGEHgvh/c2hn1EEWKNoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW4M9szr8VMg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a30575b-4a9d-454d-9e19-549574a7b1b8"
      },
      "source": [
        "#checking the propotions of 5s and 8s in the dataset to prevent biasing\n",
        "fives = (ytrain == '5').sum() + (ytest == '5').sum()\n",
        "eights = (ytrain == '8').sum() + (ytest == '8').sum()\n",
        "print(fives/eights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9141949152542372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4ytee51N8vJ"
      },
      "source": [
        "# Part 2: Training the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRumoxyOP6yl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9d609bbb-d64a-4b77-8a28-24edca3b885b"
      },
      "source": [
        "for i in [0.1, 1, 10]:\n",
        "    clf = svm.SVC(kernel='linear', C=i) \n",
        "    initial = time.time()\n",
        "    clf.fit(xtrain, ytrain)\n",
        "    final = time.time()\n",
        "    print(\"Training time for linear kernel when C =\", i ,\":\", '%.2f'%(final - initial), \"sec\")  \n",
        "\n",
        "    #error rate\n",
        "    pred = clf.predict(xtest)\n",
        "    err_rate = 1 - accuracy_score(ytest, pred)\n",
        "    print(\"Error rate for linear kernel when C =\", i ,\"is\", err_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time for linear kernel when C = 0.1 : 0.46 sec\n",
            "Error rate for linear kernel when C = 0.1 is 0.051136363636363646\n",
            "Training time for linear kernel when C = 1 : 0.44 sec\n",
            "Error rate for linear kernel when C = 1 is 0.051136363636363646\n",
            "Training time for linear kernel when C = 10 : 0.45 sec\n",
            "Error rate for linear kernel when C = 10 is 0.051136363636363646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDx0JJ18b-D"
      },
      "source": [
        "# Defining a function to train a support vector classifier for different kernels and values of regularization and gamma and displaying the metrics for each classifier trained\n",
        "def predict_svc(kernel_type,C=1, gamma=None,degree=None):\n",
        "    print((kernel_type),\"kernel\")\n",
        "    if kernel_type != 'linear':\n",
        "        print(\"Parameters: C = \",(C),\" gamma = \",(gamma),\" degree = \",(degree))\n",
        "    else:\n",
        "      print(\"Regularization Parameter = \", (C) )\n",
        "\n",
        "\n",
        "    start = time.time()\n",
        "    # Setting the regularization parameter\n",
        "    C = C \n",
        "    # Running the model and fitting the xtrain and ytrain values into the model\n",
        "    if kernel_type == 'linear':\n",
        "        clf = svm.SVC(kernel=kernel_type, C=C) \n",
        "    if kernel_type == 'rbf':\n",
        "        clf = svm.SVC(kernel=kernel_type, C=C, gamma=gamma)\n",
        "    if kernel_type == 'poly':\n",
        "        clf = svm.SVC(kernel=kernel_type, C=C, degree=degree)\n",
        "    clf.fit(xtrain,ytrain) \n",
        "    end = time.time()\n",
        "    print(\"Training time = \", (end-start))\n",
        "\n",
        "    # Running the model on the testing set to report accuracy \n",
        "    y_pred = clf.predict(xtest)\n",
        "    accuracy = accuracy_score(ytest,y_pred)\n",
        "    error_rate = 1-accuracy\n",
        "    print(\"Accuracy Score :\",(accuracy))\n",
        "    print(\"Error Rate: \", (error_rate))\n",
        "    print (\".................................................................................\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZeJ6vQh8rT4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "98634096-2df4-4346-aa29-104b76056321"
      },
      "source": [
        "C_range = [0.1, 1, 10]\n",
        "results_linear = []\n",
        "for C in C_range:\n",
        "    predict_svc('linear', C=C) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear kernel\n",
            "Regularization Parameter =  0.1\n",
            "Training time =  0.4531862735748291\n",
            "Accuracy Score : 0.9488636363636364\n",
            "Error Rate:  0.051136363636363646\n",
            ".................................................................................\n",
            "linear kernel\n",
            "Regularization Parameter =  1\n",
            "Training time =  0.439464807510376\n",
            "Accuracy Score : 0.9488636363636364\n",
            "Error Rate:  0.051136363636363646\n",
            ".................................................................................\n",
            "linear kernel\n",
            "Regularization Parameter =  10\n",
            "Training time =  0.43898630142211914\n",
            "Accuracy Score : 0.9488636363636364\n",
            "Error Rate:  0.051136363636363646\n",
            ".................................................................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovUdpei8Q7dZ"
      },
      "source": [
        "We can see that we obtain a pretty decent accuracy score just by using a linear kernel. The classifier is able to classify 94% or the data accurately. Also, changing the regularization parameter (specifying how miss-classifications are allowed) doesn't have much of an impact on the accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tYOR82T_UDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2159
        },
        "outputId": "65f03b70-7ccc-45e1-c5b4-362dd9daa06c"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "degrees = [2,3,4,5,7,15,50]\n",
        "results_polys = []\n",
        "for degree in degrees:\n",
        "    for C in [0.01,1,10]:\n",
        "        predict_svc('poly', C=C, degree = degree) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  2\n",
            "Training time =  0.4945211410522461\n",
            "Accuracy Score : 0.9886363636363636\n",
            "Error Rate:  0.011363636363636354\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  2\n",
            "Training time =  0.4910752773284912\n",
            "Accuracy Score : 0.9886363636363636\n",
            "Error Rate:  0.011363636363636354\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  2\n",
            "Training time =  0.4934709072113037\n",
            "Accuracy Score : 0.9886363636363636\n",
            "Error Rate:  0.011363636363636354\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  3\n",
            "Training time =  0.5241835117340088\n",
            "Accuracy Score : 0.9857954545454546\n",
            "Error Rate:  0.014204545454545414\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  3\n",
            "Training time =  0.5304546356201172\n",
            "Accuracy Score : 0.9857954545454546\n",
            "Error Rate:  0.014204545454545414\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  3\n",
            "Training time =  0.5260062217712402\n",
            "Accuracy Score : 0.9857954545454546\n",
            "Error Rate:  0.014204545454545414\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  4\n",
            "Training time =  0.5657181739807129\n",
            "Accuracy Score : 0.9857954545454546\n",
            "Error Rate:  0.014204545454545414\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  4\n",
            "Training time =  0.5636389255523682\n",
            "Accuracy Score : 0.9857954545454546\n",
            "Error Rate:  0.014204545454545414\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  4\n",
            "Training time =  0.5629382133483887\n",
            "Accuracy Score : 0.9857954545454546\n",
            "Error Rate:  0.014204545454545414\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  5\n",
            "Training time =  0.6511061191558838\n",
            "Accuracy Score : 0.96875\n",
            "Error Rate:  0.03125\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  5\n",
            "Training time =  0.6551668643951416\n",
            "Accuracy Score : 0.96875\n",
            "Error Rate:  0.03125\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  5\n",
            "Training time =  0.6544065475463867\n",
            "Accuracy Score : 0.96875\n",
            "Error Rate:  0.03125\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  7\n",
            "Training time =  0.800137996673584\n",
            "Accuracy Score : 0.9403409090909091\n",
            "Error Rate:  0.05965909090909094\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  7\n",
            "Training time =  0.8017675876617432\n",
            "Accuracy Score : 0.9403409090909091\n",
            "Error Rate:  0.05965909090909094\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  7\n",
            "Training time =  0.7973108291625977\n",
            "Accuracy Score : 0.9403409090909091\n",
            "Error Rate:  0.05965909090909094\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  15\n",
            "Training time =  0.01478123664855957\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  15\n",
            "Training time =  0.019042253494262695\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  15\n",
            "Training time =  0.012327432632446289\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  0.01  gamma =  None  degree =  50\n",
            "Training time =  0.01183629035949707\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  1  gamma =  None  degree =  50\n",
            "Training time =  0.012745857238769531\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "poly kernel\n",
            "Parameters: C =  10  gamma =  None  degree =  50\n",
            "Training time =  0.013370037078857422\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrEpIe3pRpWr"
      },
      "source": [
        "Through the results above, we can see that the best classification accuracy is achieved when we usa a polynomial kernel with a low degree. Hence, increasing the complexity of our classifier in this case yielded us with better results.  However, the model accuracy drops as the degree is increased, with very low accuracy levels at degrees greater than 15. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-1x6T8a_e3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        },
        "outputId": "488f3d91-f3ee-4501-f042-e4421fefafdf"
      },
      "source": [
        "\"\"\" RBF KERNEL \"\"\"\n",
        "results_rbfs = []\n",
        "for gamma in [0.001,0.1,1,10,100,'auto']:\n",
        "    for C in [0.01,1,10]:\n",
        "        predict_svc('rbf',C=C,gamma=gamma) \n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rbf kernel\n",
            "Parameters: C =  0.01  gamma =  0.001  degree =  None\n",
            "Training time =  2.610102653503418\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  1  gamma =  0.001  degree =  None\n",
            "Training time =  2.6051716804504395\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  10  gamma =  0.001  degree =  None\n",
            "Training time =  2.5894010066986084\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  0.01  gamma =  0.1  degree =  None\n",
            "Training time =  2.5965514183044434\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  1  gamma =  0.1  degree =  None\n",
            "Training time =  2.597097873687744\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  10  gamma =  0.1  degree =  None\n",
            "Training time =  2.603787422180176\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  0.01  gamma =  1  degree =  None\n",
            "Training time =  2.6267426013946533\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  1  gamma =  1  degree =  None\n",
            "Training time =  2.599684000015259\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  10  gamma =  1  degree =  None\n",
            "Training time =  2.595083475112915\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  0.01  gamma =  10  degree =  None\n",
            "Training time =  2.586045980453491\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  1  gamma =  10  degree =  None\n",
            "Training time =  2.614553689956665\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  10  gamma =  10  degree =  None\n",
            "Training time =  2.607135057449341\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  0.01  gamma =  100  degree =  None\n",
            "Training time =  2.5814690589904785\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  1  gamma =  100  degree =  None\n",
            "Training time =  2.599937915802002\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  10  gamma =  100  degree =  None\n",
            "Training time =  2.5989186763763428\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  0.01  gamma =  auto  degree =  None\n",
            "Training time =  2.608247995376587\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  1  gamma =  auto  degree =  None\n",
            "Training time =  2.615640878677368\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n",
            "rbf kernel\n",
            "Parameters: C =  10  gamma =  auto  degree =  None\n",
            "Training time =  2.5948121547698975\n",
            "Accuracy Score : 0.48863636363636365\n",
            "Error Rate:  0.5113636363636364\n",
            ".................................................................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq4QDRFWQfDE"
      },
      "source": [
        "However, in the case of Radial Basis Function kernel, we see that sometimes increasing the complexity can result in lower accuracy levels as rbf kernel performs poorly for every defined parameters. This is because the data can only be seperated best at a certain dimension and taking it to other dimension will not have any affect on the classification. "
      ]
    }
  ]
}